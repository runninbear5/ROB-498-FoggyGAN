# ROB-498-FoggyGAN
This Model was an extension of the paper Deep-WaveNet-Underwater-Image-Restoration.

The goal of this model is to restore foggy images to be used with self driving cars.

## Colab Notebooks for Streamlined Testing and Training
Testing: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10SaXf-RU5M3X20gxdT8FU9bMSQfnAzeE#scrollTo=GBOb1zRbII-Z)

Training: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]([https://colab.research.google.com/drive/10SaXf-RU5M3X20gxdT8FU9bMSQfnAzeE#scrollTo=GBOb1zRbII-Z](https://colab.research.google.com/drive/169w6pYdfSgdUkYB5ZpmBqAoOgFLwkwfM#scrollTo=FkOpJC5-pL92))

## Demo Videos
[5-5-5 Model Demo](https://www.youtube.com/watch?v=y9Q6KKBxgrI)

[5-5-5 Model Demo Comparison](https://www.youtube.com/watch?v=IoQ2-rlWHsc)

[5-5-5-Heavy Model Demo Comparison](https://www.youtube.com/watch?v=E-q5KhJ4N-)

## Citations
M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, “The Cityscapes Dataset for Semantic Urban Scene Understanding,” in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.

[main paper](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf) · [supplemental](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes-supplemental.pdf) · [arxiv](http://arxiv.org/abs/1604.01685) · [CVF](http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Cordts_The_Cityscapes_Dataset_CVPR_2016_paper.html)

```
@misc{sharma2021wavelengthbased, title={Wavelength-based Attributed Deep
Neural Network for Underwater Image Restoration}, author={Prasen Kumar
Sharma and Ira Bisht and Arijit Sur}, year={2021}, eprint={2106.07910},
archivePrefix={arXiv}, primaryClass={eess.IV} }

@article{islam2019fast, title={Fast Underwater Image Enhancement for
Improved Visual Perception}, author={Islam, Md Jahidul and Xia, Youya
and Sattar, Junaed}, journal={IEEE Robotics and Automation Letters
(RA-L)}, volume={5}, number={2}, pages={3227--3234}, year={2020},
publisher={IEEE} }

@ARTICLE{8917818,\
author={Li, Chongyi and Guo, Chunle and Ren, Wenqi and Cong, Runmin and
Hou, Junhui and Kwong, Sam and Tao, Dacheng},\
journal={IEEE Transactions on Image Processing},\
title={An Underwater Image Enhancement Benchmark Dataset and Beyond},\
year={2020},\
volume={29},\
number={},\
pages={4376-4389},\
doi={10.1109/TIP.2019.2955241} }

@inproceedings{eriba2019kornia, author = {E. Riba, D. Mishkin, D. Ponsa,
E. Rublee and G. Bradski}, title = {Kornia: an Open Source
Differentiable Computer Vision Library for PyTorch}, booktitle = {Winter
Conference on Applications of Computer Vision}, year = {2020}, url =
{https://arxiv.org/pdf/1910.02190.pdf} }

@inproceedings{islam2020suim, title={{Semantic Segmentation of
Underwater Imagery: Dataset and Benchmark}}, author={Islam, Md Jahidul
and Edge, Chelsey and Xiao, Yuyang and Luo, Peigen and Mehtaz, Muntaqim
and Morse, Christopher and Enan, Sadman Sakib and Sattar, Junaed},
booktitle={IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS)}, year={2020}, organization={IEEE/RSJ} }

@article{8765346, author = {Z. {Cao} and G. {Hidalgo Martinez} and T.
{Simon} and S. {Wei} and Y. A. {Sheikh}}, journal = {IEEE Transactions
on Pattern Analysis and Machine Intelligence}, title = {OpenPose:
Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
year = {2019} }
```
